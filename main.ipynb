{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "sample_recording = True\n",
    "all_data = loadmat('data/sample_1.mat')\n",
    "sample_data = np.array(all_data['data'])\n",
    "\n",
    "# sample_data = np.array([np.load('data/recording.npy')])\n",
    "# print(sample_data.shape)\n",
    "\n",
    "# extract spike times for later comparison\n",
    "spike_times = np.array(all_data['spike_times'])\n",
    "print('# of actual spikes (ground truth):', len(spike_times[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "seconds = 120\n",
    "sr = 24000 # sample rate = 24kHz (For sample recordings) / 32051 for real recording\n",
    "\n",
    "data = sample_data[0][:round(seconds*sr)]\n",
    "ground_truth_spikes = spike_times[0][0][0][:round(seconds*sr)]\n",
    "\n",
    "mean_data = np.mean(data)\n",
    "std_data = np.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_spikes(data, multiplier):\n",
    "    spike_times_start_only = []\n",
    "    spike_times_reconstructed = np.where(data >= np.mean(data) + multiplier * np.std(data))[0]\n",
    "    \n",
    "    if len(spike_times_reconstructed) > 0:\n",
    "        spike_times_start_only.append(spike_times_reconstructed[0])\n",
    "        spike_times_start_only.extend(spike_times_reconstructed[np.where(np.diff(spike_times_reconstructed) > 10)[0]+1])\n",
    "\n",
    "    return np.array(spike_times_start_only)\n",
    "\n",
    "\n",
    "def calculate_f1_score(detected_spikes, ground_truth_spikes, sr, tolerance=0.01):\n",
    "    # convert tolerance (time duration in seconds: 0.001 = 1ms) to number of samples\n",
    "    tolerance_in_samples = tolerance * sr\n",
    "    detected_binary = np.zeros_like(data)\n",
    "\n",
    "    # set values to 1 where spikes occur (detected_binary[start_index:end_index] = 1)\n",
    "    for spike in (detected_spikes / sr):\n",
    "        detected_binary[int(spike * sr - tolerance_in_samples): int(spike * sr + tolerance_in_samples)] = 1\n",
    "\n",
    "    ground_truth_binary = np.zeros_like(data)\n",
    "    for spike in (ground_truth_spikes / sr):\n",
    "        ground_truth_binary[int(spike * sr - tolerance_in_samples): int(spike * sr + tolerance_in_samples)] = 1\n",
    "\n",
    "    # calculate F1 score\n",
    "    f1 = f1_score(ground_truth_binary, detected_binary)\n",
    "\n",
    "    # confusion matrix\n",
    "    conf_matrix = confusion_matrix(ground_truth_binary, detected_binary)\n",
    "    \n",
    "    return f1, conf_matrix\n",
    "\n",
    "\n",
    "# test different multiplier values for threshold\n",
    "multipliers = np.arange(0.0, 4.0, 0.1) \n",
    "f1_scores = []\n",
    "best_f1, best_conf = 0, None\n",
    "\n",
    "for multiplier in multipliers:\n",
    "    detected_spikes = detect_spikes(data, multiplier)\n",
    "    f1, conf = calculate_f1_score(detected_spikes, spike_times[0][0][0][:round(seconds*sr)], sr)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_conf = conf\n",
    "\n",
    "\n",
    "# plot F1 scores as a function of the multiplier\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(multipliers, f1_scores, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Multiplier')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# get best multiplier based on F1 score\n",
    "best_f1 = max(f1_scores)\n",
    "best_multiplier = multipliers[np.argmax(f1_scores)]\n",
    "\n",
    "# for better formatting\n",
    "conf_df = pd.DataFrame(best_conf, index=[\"Actual No Spike\", \"Actual Spike\"], columns=[\"Predicted No Spike\", \"Predicted Spike\"])\n",
    "\n",
    "print(f\"Best multiplier: {best_multiplier}, F1 score: {best_f1}\")\n",
    "print(conf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply threshold to raw data\n",
    "spike_times_reconstructed = np.where(data >= mean_data + best_multiplier * std_data)[0]\n",
    "print(mean_data + best_multiplier * std_data)\n",
    "spike_times_start_only = []\n",
    "spike_times_start_only.append(spike_times_reconstructed[0])\n",
    "# if data is above threshold back to back, count all occurences as one single spike\n",
    "spike_times_start_only.extend(spike_times_reconstructed[np.where(np.diff(spike_times_reconstructed) > 10)[0]+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only runs this cell if seconds parameter is below 5, otherwise the plot gets too convoluted\n",
    "if seconds < 5:\n",
    "    # display data\n",
    "    plt.figure(figsize=(25,6))\n",
    "    plt.plot(np.linspace(0, seconds, round(seconds*sr)), data)\n",
    "    plt.xlim(0, seconds)\n",
    "\n",
    "    # plot where we think a spike is \n",
    "    for i, spike in enumerate(spike_times_start_only):\n",
    "        # plt.axvline(spike/sr - .0008, c='red', alpha=0.5)\n",
    "        plt.axvspan(spike/sr - .0008, spike/sr + .001, facecolor='r', alpha=0.2)\n",
    "        plt.text(spike/sr - 0.006, 110 if i%2 == 0 else 100, i+1, c='r')\n",
    "\n",
    "    # plot ground truth for reference\n",
    "    for i, spike in enumerate(ground_truth_spikes / sr):\n",
    "        if round(spike*24000) > round(seconds*24000): break\n",
    "        plt.axvline(spike, c='k', alpha=1)\n",
    "        plt.text(spike - 0.006, 85 if i%2 == 0 else 75, i+1, c='b')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_spikes = len(spike_times_start_only)\n",
    "\n",
    "# get max & min voltage of all spikes (for plotting purposes)\n",
    "ymax = 0\n",
    "ymin = 0\n",
    "spikes = []\n",
    "detected_spike_times = []\n",
    "for spike in spike_times_start_only:\n",
    "    start = round(spike - .0008 * sr)\n",
    "    end = round(spike + .001 * sr)\n",
    "    if np.max(data[start:end]) > ymax: ymax = np.max(data[start:end])\n",
    "    if np.min(data[start:end]) < ymin: ymin = np.min(data[start:end])\n",
    "    # store detected spikes in list\n",
    "    spikes.append(data[start:end])\n",
    "    detected_spike_times.append(start)\n",
    "\n",
    "\n",
    "if sample_recording:\n",
    "    hit_or_miss = np.zeros(len(detected_spike_times))\n",
    "    for i, spike in enumerate(detected_spike_times):\n",
    "        matching = [x for x in spike_times[0][0][0] if spike - 10 <= x <= spike + 43]\n",
    "        if matching:\n",
    "            hit_or_miss[i] = 1\n",
    "        else:\n",
    "            hit_or_miss[i] = 0\n",
    "    print(len(np.where(hit_or_miss == 1)[0])/len(spike_times[0][0][0]))\n",
    "    \n",
    "inertias = []\n",
    "# determine best number of clusters via elbow plot\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, n_init='auto')\n",
    "    kmeans.fit(spikes)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 11), inertias, marker='o')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "range_n_clusters = [x for x in range(2, 11)]\n",
    "for n_clusters in range_n_clusters:\n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(5, 5)\n",
    "\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_ylim([0, len(spikes) + (n_clusters + 1) * 10])\n",
    "\n",
    "    clusterer = KMeans(n_clusters=n_clusters, n_init=\"auto\")\n",
    "    cluster_labels = clusterer.fit_predict(spikes)\n",
    "    silhouette_avg = silhouette_score(spikes, cluster_labels)\n",
    "\n",
    "    sample_silhouette_values = silhouette_samples(spikes, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply final clustering algorithm based on optimal number of clusters\n",
    "n_clusters = 3\n",
    "kmeans_final = KMeans(n_init='auto', n_clusters=n_clusters)\n",
    "classes = kmeans_final.fit_predict(spikes)\n",
    "colors = ['r', 'g', 'b', 'orange']\n",
    "\n",
    "# plot first 20 spikes in different colors to see if clustering worked\n",
    "plt.figure(figsize=(30,10))\n",
    "for i, spike in enumerate(spikes[:20]):\n",
    "    plt.subplot(5, 4, i+1)\n",
    "    plt.grid()\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.plot(spike, c=colors[classes[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5*n_clusters, 4))\n",
    "\n",
    "print('# of spikes:', number_of_spikes)\n",
    "\n",
    "# compute mean & std deviation of each spike class & plot them\n",
    "for i in range(n_clusters):\n",
    "    length = 43 if sample_recording else 58 # 43 for sr=24000, 58 for sr=32051\n",
    "    x = np.arange(0, length, 1)\n",
    "    classIndices = np.where(classes == i)[0]\n",
    "    \n",
    "    meanSpike = np.mean(np.array(spikes)[classIndices], axis=0)\n",
    "    deviation = np.std(np.array(spikes)[classIndices])\n",
    "    \n",
    "    plt.subplot(1, n_clusters, i+1)\n",
    "    plt.title(f'# of spikes in cluster: {len(classIndices)}')\n",
    "    plt.plot(meanSpike)\n",
    "    plt.fill_between(x, meanSpike - deviation, meanSpike + deviation, alpha=0.1, color='r')\n",
    "    plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "20e40d8fc09a6690434ad602c7eb2d8de15d36ec466bfbfb0de97c7c540d7363"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
