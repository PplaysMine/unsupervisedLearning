{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn_sfa_master.sksfa import HSFA\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data & crop / reduce size if dim_step > 1\n",
    "data = np.load('data/data_squareRoom.npy')\n",
    "crop_h = 20\n",
    "crop_w = 10\n",
    "dim_step= 1\n",
    "data = data[:, crop_h:-crop_h, crop_w:-crop_w][:, ::dim_step][:, :, ::dim_step]\n",
    "gc.collect()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize images\n",
    "images = np.array([(image - image.min()) / (image.max() - image.min()) for image in data])\n",
    "print(images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init. HSFA (Skip this step if you want to load the pre-trained model)\n",
    "layer_configurations = [(10, 10, 5, 5, 5, 2)]\n",
    "hsfa = HSFA(10, images.shape[1:], layer_configurations, verbose=True)\n",
    "hsfa = hsfa.fit(images)\n",
    "slow_features = hsfa.transform(images)\n",
    "\n",
    "with open(\"hsfa.pkl\", \"wb\") as file:\n",
    "    pickle.dump(hsfa, file)\n",
    "np.save(\"slow_features.npy\", slow_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained hsfa\n",
    "with open(\"hsfa.pkl\", \"rb\") as file:\n",
    "    hsfa = pickle.load(file)\n",
    "print(hsfa.summary())\n",
    "slow_features = np.load(\"slow_features.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 5 slowest features\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "# Compare two images \n",
    "index1 = 67\n",
    "index2 = index1+1\n",
    "\n",
    "ax.plot(slow_features[:, 0], label=\"Slow Feature 1\")\n",
    "ax.plot(slow_features[:, 1], label=\"Slow Feature 2\")\n",
    "ax.plot(slow_features[:, 2], label=\"Slow Feature 3\")\n",
    "ax.plot(slow_features[:, 3], label=\"Slow Feature 4\")\n",
    "print('pos 1:', slow_features[index1])\n",
    "print('pos 2:', slow_features[index2])\n",
    "print('Change:', np.abs(slow_features[index1] - slow_features[index2]))\n",
    "print(f'Max diff.: Slow feature #{np.argmax(np.abs(slow_features[index1] - slow_features[index2])) + 1}')\n",
    "ax.legend()\n",
    "ax.grid(alpha=.3)\n",
    "hline = ax.axvline(index1, c='r', alpha=.5, linestyle='--')\n",
    "hline = ax.axvline(index2, c='g', alpha=.5, linestyle='--')\n",
    "plt.title(\"Extracted Slow Features\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Feature Value\")\n",
    "length = 200\n",
    "steps = 4\n",
    "plt.xlim(0,length)\n",
    "plt.xticks(np.arange(0, length, steps))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(data[index1])\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(data[index2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of first 4 features (not really useful)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(slow_features[:,0], slow_features[:,1], slow_features[:,2], c=slow_features[:,3], cmap='viridis', alpha=0.6)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init. SOM & find winners\n",
    "\n",
    "from minisom import MiniSom\n",
    "from tqdm.notebook import tqdm\n",
    "print(round(np.sqrt(100**2 + 100**2)))\n",
    "som = MiniSom(200, 200, 9, sigma=3, learning_rate=0.3, random_seed=42)\n",
    "som.random_weights_init(slow_features[:,1:10])\n",
    "som.train(slow_features[:,1:10], 5000, random_order=True, verbose=True)\n",
    "winners = [som.winner(x) for x in tqdm(slow_features[:,1:10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot SOM & compare two images\n",
    "\n",
    "index = 45\n",
    "index2 = index+1\n",
    "winners = np.array(winners)\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# ax.scatter(winners[:,0], winners[:,1], slow_features[:,0], marker='.', c='black', alpha=.1)\n",
    "# ax.plot(winners[index,0], winners[index,1], slow_features[index,0], 'ro', label='first image')\n",
    "# ax.plot(winners[index2,0], winners[index2,1], slow_features[index2,0], 'bo', label='second image')\n",
    "# ax.legend()\n",
    "# ax.view_init(elev=30, azim=-45)\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "combined = slow_features[:,0]\n",
    "scaledRotation = (combined - np.min(combined)) / (np.max(combined) - np.min(combined))\n",
    "\n",
    "plt.scatter(winners[:,0], winners[:,1], marker='.', c=scaledRotation, cmap='viridis', alpha=.6)\n",
    "cbar = plt.colorbar()\n",
    "plt.plot(winners[index,0], winners[index,1], 'ro', label='first image', markersize=10)\n",
    "plt.plot(winners[index2,0], winners[index2,1], c='orange', marker='o', label='second image', markersize=10)\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title(\"SOM w/ 4 features (rotation = color)\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(data[index])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(data[index2])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Use own recorded data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load recorded data & stitch them together, outcome: dataset w/ shape (3000, 30, 190, 3)\n",
    "# & perform SFA\n",
    "\n",
    "recorded_data = []\n",
    "pos_data = []\n",
    "\n",
    "camera_only_rot = np.load('recorded_data/dataset/camera_only_rot.npy')\n",
    "camera_no_rot = np.load('recorded_data/dataset/camera_no_rot.npy')\n",
    "camera = np.load('recorded_data/dataset/camera.npy')\n",
    "\n",
    "pos_only_rot = np.load('recorded_data/dataset/position_only_rot.npy')\n",
    "pos_no_rot = np.load('recorded_data/dataset/position_no_rot.npy')\n",
    "pos = np.load('recorded_data/dataset/position.npy')\n",
    "\n",
    "dataset = np.zeros((3000, 30, 190, 3))\n",
    "positions = np.zeros((3000,4))\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    if i < 1000:\n",
    "        dataset[i] = camera_only_rot[i]\n",
    "        positions[i] = pos_only_rot[i]\n",
    "    elif i < 2000:\n",
    "        dataset[i] = camera_no_rot[i-1000]\n",
    "        positions[i] = pos_no_rot[i-1000]\n",
    "    else:\n",
    "        dataset[i] = camera[i-2000]\n",
    "        positions[i] = pos[i-2000]\n",
    "\n",
    "images_own = np.array([(image - image.min()) / (image.max() - image.min()) for image in dataset])\n",
    "print(images_own.shape)\n",
    "slow_features_own_dataset = hsfa.transform(images_own)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot three slowest features\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(slow_features_own_dataset[:,0], label='sf#1')\n",
    "plt.plot(slow_features_own_dataset[:,1])\n",
    "plt.plot(slow_features_own_dataset[:,2])\n",
    "plt.xlim([0, 200])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.imshow(images[25])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.figure()\n",
    "plt.imshow(images[26])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "print(positions[100], positions[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOM for recorded data\n",
    "winners = [som.winner(x) for x in tqdm(slow_features_own_dataset[:,1:10])]\n",
    "winners = np.array(winners)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(winners[:,0], winners[:,1], c=slow_features_own_dataset[:,0], cmap='viridis', marker='.', alpha=1)\n",
    "plt.title(\"Pre-trained pipeline (HSFA [10 features], SOM) applied to own dataset\")\n",
    "plt.plot()\n",
    "plt.colorbar()\n",
    "\n",
    "index = 25\n",
    "index2 = 26\n",
    "\n",
    "plt.plot(winners[index,0], winners[index,1], 'ro', label='first image', markersize=10)\n",
    "plt.plot(winners[index2,0], winners[index2,1], c='orange', marker='o', label='second image', markersize=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "20e40d8fc09a6690434ad602c7eb2d8de15d36ec466bfbfb0de97c7c540d7363"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
